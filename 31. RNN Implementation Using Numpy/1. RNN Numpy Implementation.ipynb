{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Recurrent neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://www.analyticsvidhya.com/blog/2017/12/introduction-to-recurrent-neural-networks/\n",
    "- http://adventuresinmachinelearning.com/recurrent-neural-networks-lstm-tutorial-tensorflow/\n",
    "- http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A recurrent neural network (RNN) is a type of advanced artificial neural network (ANN) that involves directed cycles in memory. One aspect of recurrent neural networks is the ability to build on earlier types of networks with fixed-size input vectors and output vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A RNN simply uses previous input sources within the calculations. Say we are analysing handwriting, we can predict words and future letters much better if we remember the previous letters. If we are highly confident the person wrote “win”, we can use that to help decypher future w’s, i’s, and n’s, as they will likely look very similar to the characters used in that word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we are gonna build a simple rnn which will do simple binary addition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [objective]\n",
    "\n",
    "- Understand RNN with a simple numpy implementation.\n",
    "- Train RNN for a binary opperation, e.g. addition.\n",
    "- Check if the trained RNN can be extended for the unseen data with longer digits (e.g. 8 bytes digits training -> 10 bytes digit test)\n",
    "\n",
    "![binaryadd](binary_addition.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First we will import our libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import copy, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(0)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that we will define our activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "def sigmoid(x):\n",
    "    output =1/(1+np.exp(-x))\n",
    "    return output\n",
    "\n",
    "def sigmoid_output_to_derivative(output):    \n",
    "    return output*(1-output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will decide the binary dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n",
      "256\n",
      "range(0, 8)\n"
     ]
    }
   ],
   "source": [
    "# Decide the maximum binary dimension \n",
    "max_binary_dim = 8\n",
    "largest_number = pow(2,max_binary_dim)\n",
    "print(2**8)\n",
    "print(pow(2,max_binary_dim))\n",
    "print(range(2**3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create binary lookup table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 0 0 0]\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "# Create binary lookup table\n",
    "# np.unpackbits e.g.\n",
    "print(np.unpackbits(np.array([8], dtype = np.uint8)))\n",
    "print(\"====================\")\n",
    "\n",
    "# e.g\n",
    "# binary_gonna_be = np.array([range(largest_number)], dtype=np.uint8).T\n",
    "# print(binary_gonna_be)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 8) [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 1 0]\n",
      " ...\n",
      " [1 1 1 ... 1 0 1]\n",
      " [1 1 1 ... 1 1 0]\n",
      " [1 1 1 ... 1 1 1]]\n",
      "====================\n",
      "lookup table test\n",
      "[0 0 0 0 0 0 1 1] [0 0 0 0 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "#   binary lookup table\n",
    "binary = np.unpackbits(np.array([range(largest_number)], dtype=np.uint8).T, axis = 1)\n",
    "print(binary.shape, binary)\n",
    "print(\"====================\")\n",
    "int2binary = {}\n",
    "for i in range(largest_number):\n",
    "    int2binary[i] = binary[i]\n",
    "print(\"lookup table test\")\n",
    "print(binary[3], int2binary[3])\n",
    "#print(int2binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial parameter setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 16) (16, 1) (16, 16)\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.1 # learning rate\n",
    "input_dim = 2 #  digit  input이 \n",
    "hidden_dim = 16 # we can vary this and see what happens\n",
    "output_dim = 1 # output one dim e.g. 1(2) + 1(2) = 0(2) with overflow 1\n",
    "\n",
    "# weight initialization\n",
    "synapse_0 = 2*np.random.random((input_dim,hidden_dim))-1\n",
    "synapse_1 = 2*np.random.random((hidden_dim,output_dim))-1\n",
    "synapse_h = 2*np.random.random((hidden_dim,hidden_dim))-1\n",
    "\n",
    "print(synapse_0.shape, synapse_1.shape, synapse_h.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving for updates and visualization\n",
    "s0_update = np.zeros(synapse_0.shape) # s0_update = np.zeros_like(synapse_0)\n",
    "s1_update = np.zeros(synapse_1.shape) \n",
    "sh_update = np.zeros(synapse_h.shape) \n",
    "\n",
    "overallError_history = list()\n",
    "accuracy = list()\n",
    "accuracy_history = list()\n",
    "accuracy_count = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:[3.97540736]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 1 0 0 0 1 1 1]\n",
      "False\n",
      "10 + 61 = 0\n",
      "------------\n",
      "Error:[4.0325467]\n",
      "Pred:[0 1 1 0 1 1 0 1]\n",
      "True:[1 0 0 1 0 1 0 1]\n",
      "False\n",
      "111 + 38 = 109\n",
      "------------\n",
      "Error:[3.79424599]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 1 1 1 0 0 0]\n",
      "False\n",
      "55 + 1 = 0\n",
      "------------\n",
      "Error:[3.87395152]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 0 1 1 0 0 1]\n",
      "False\n",
      "20 + 5 = 0\n",
      "------------\n",
      "Error:[4.01458433]\n",
      "Pred:[1 1 1 1 1 1 1 1]\n",
      "True:[0 1 0 1 0 1 1 0]\n",
      "False\n",
      "12 + 74 = 255\n",
      "------------\n",
      "Error:[3.99141219]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 1 1 0 0 0 1 0]\n",
      "False\n",
      "30 + 68 = 0\n",
      "------------\n",
      "Error:[3.97121353]\n",
      "Pred:[0 0 0 0 1 0 0 0]\n",
      "True:[0 0 1 0 0 0 0 1]\n",
      "False\n",
      "28 + 5 = 8\n",
      "------------\n",
      "Error:[4.02250446]\n",
      "Pred:[1 1 1 1 1 1 1 0]\n",
      "True:[0 1 0 1 1 0 1 1]\n",
      "False\n",
      "60 + 31 = 254\n",
      "------------\n",
      "Error:[4.04634296]\n",
      "Pred:[1 1 0 1 0 1 0 1]\n",
      "True:[0 1 1 1 1 1 1 1]\n",
      "False\n",
      "23 + 104 = 213\n",
      "------------\n",
      "Error:[3.87790083]\n",
      "Pred:[1 0 1 1 1 1 1 0]\n",
      "True:[1 1 0 1 0 1 1 0]\n",
      "False\n",
      "124 + 90 = 190\n",
      "------------\n",
      "Error:[3.8993887]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 1 0 1 0 1 0 1]\n",
      "False\n",
      "75 + 10 = 0\n",
      "------------\n",
      "Error:[4.00422894]\n",
      "Pred:[0 0 0 0 0 0 1 0]\n",
      "True:[0 0 0 0 0 1 0 1]\n",
      "False\n",
      "4 + 1 = 2\n",
      "------------\n",
      "Error:[3.97174173]\n",
      "Pred:[0 1 1 0 0 1 1 0]\n",
      "True:[1 0 0 0 0 0 1 0]\n",
      "False\n",
      "15 + 115 = 102\n",
      "------------\n",
      "Error:[4.08583973]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 1 1 0 1 1 0 0]\n",
      "False\n",
      "95 + 13 = 0\n",
      "------------\n",
      "Error:[4.20674656]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 1 1 1 0 1 1 1]\n",
      "False\n",
      "28 + 91 = 0\n",
      "------------\n",
      "Error:[4.25291382]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 1 1 1 1 1 1 0]\n",
      "False\n",
      "88 + 38 = 0\n",
      "------------\n",
      "Error:[3.53099877]\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 1 0 0 1 0 0 0]\n",
      "False\n",
      "40 + 32 = 0\n",
      "------------\n",
      "Error:[3.89231997]\n",
      "Pred:[1 1 1 1 1 1 1 1]\n",
      "True:[1 0 1 1 0 1 0 1]\n",
      "False\n",
      "79 + 102 = 255\n",
      "------------\n",
      "Error:[4.02295019]\n",
      "Pred:[0 1 0 0 1 1 1 1]\n",
      "True:[0 1 1 1 0 0 1 0]\n",
      "False\n",
      "75 + 39 = 79\n",
      "------------\n",
      "Error:[3.880903]\n",
      "Pred:[1 1 1 1 1 1 0 1]\n",
      "True:[0 1 1 0 1 1 0 1]\n",
      "False\n",
      "105 + 4 = 253\n",
      "------------\n",
      "Error:[3.92571431]\n",
      "Pred:[1 1 1 1 1 1 1 1]\n",
      "True:[1 0 0 1 1 0 1 1]\n",
      "False\n",
      "32 + 123 = 255\n",
      "------------\n",
      "Error:[3.7589035]\n",
      "Pred:[0 1 0 0 1 0 1 0]\n",
      "True:[1 0 0 0 1 1 1 0]\n",
      "False\n",
      "39 + 103 = 74\n",
      "------------\n",
      "Error:[3.87579648]\n",
      "Pred:[1 1 1 1 1 0 1 0]\n",
      "True:[1 0 1 0 1 0 1 1]\n",
      "False\n",
      "58 + 113 = 250\n",
      "------------\n",
      "Error:[4.19142604]\n",
      "Pred:[0 0 0 0 1 1 0 0]\n",
      "True:[0 1 1 1 0 1 0 1]\n",
      "False\n",
      "31 + 86 = 12\n",
      "------------\n",
      "Error:[3.86476286]\n",
      "Pred:[0 0 1 1 0 0 1 0]\n",
      "True:[0 0 1 1 1 1 1 0]\n",
      "False\n",
      "5 + 57 = 50\n",
      "------------\n",
      "Error:[4.05545722]\n",
      "Pred:[1 1 0 1 1 1 1 1]\n",
      "True:[1 0 0 1 0 1 0 1]\n",
      "False\n",
      "38 + 111 = 223\n",
      "------------\n",
      "Error:[4.11675483]\n",
      "Pred:[1 1 1 1 1 1 1 1]\n",
      "True:[1 0 1 0 0 0 0 1]\n",
      "False\n",
      "95 + 66 = 255\n",
      "------------\n",
      "Error:[3.90005213]\n",
      "Pred:[1 0 0 0 0 0 1 1]\n",
      "True:[1 1 1 0 1 1 1 1]\n",
      "False\n",
      "120 + 119 = 131\n",
      "------------\n",
      "Error:[4.16466363]\n",
      "Pred:[0 0 1 1 0 0 1 1]\n",
      "True:[1 0 0 1 0 1 1 0]\n",
      "False\n",
      "121 + 29 = 51\n",
      "------------\n",
      "Error:[3.76799453]\n",
      "Pred:[0 0 0 1 1 0 0 0]\n",
      "True:[0 1 1 0 1 0 0 0]\n",
      "False\n",
      "12 + 92 = 24\n",
      "------------\n",
      "Error:[3.74916647]\n",
      "Pred:[1 1 1 1 0 1 1 0]\n",
      "True:[0 1 1 1 0 1 1 0]\n",
      "False\n",
      "10 + 108 = 246\n",
      "------------\n",
      "Error:[4.19330056]\n",
      "Pred:[0 1 1 1 1 1 1 0]\n",
      "True:[1 0 0 0 0 1 1 0]\n",
      "False\n",
      "72 + 62 = 126\n",
      "------------\n",
      "Error:[3.63455126]\n",
      "Pred:[1 1 0 1 1 1 1 0]\n",
      "True:[0 1 0 1 0 1 1 0]\n",
      "False\n",
      "72 + 14 = 222\n",
      "------------\n",
      "Error:[3.79994751]\n",
      "Pred:[1 1 0 0 1 1 1 0]\n",
      "True:[1 1 0 0 1 1 0 0]\n",
      "False\n",
      "97 + 107 = 206\n",
      "------------\n",
      "Error:[3.62919201]\n",
      "Pred:[1 0 0 0 1 0 1 0]\n",
      "True:[1 0 1 1 1 0 1 0]\n",
      "False\n",
      "112 + 74 = 138\n",
      "------------\n",
      "Error:[3.73175955]\n",
      "Pred:[0 0 1 0 0 0 0 0]\n",
      "True:[0 1 0 1 0 1 1 0]\n",
      "False\n",
      "28 + 58 = 32\n",
      "------------\n",
      "Error:[3.37270867]\n",
      "Pred:[0 1 0 1 1 0 1 1]\n",
      "True:[0 1 0 1 0 0 1 1]\n",
      "False\n",
      "12 + 71 = 91\n",
      "------------\n",
      "Error:[3.42578141]\n",
      "Pred:[1 0 0 1 1 1 1 1]\n",
      "True:[1 0 0 1 1 1 1 1]\n",
      "True\n",
      "93 + 66 = 159\n",
      "------------\n",
      "Error:[3.96962954]\n",
      "Pred:[0 0 1 1 0 1 1 0]\n",
      "True:[0 1 0 0 1 0 0 0]\n",
      "False\n",
      "63 + 9 = 54\n",
      "------------\n",
      "Error:[3.20748485]\n",
      "Pred:[1 1 1 0 1 1 1 1]\n",
      "True:[0 1 1 0 1 1 1 1]\n",
      "False\n",
      "15 + 96 = 239\n",
      "------------\n",
      "Error:[3.07873713]\n",
      "Pred:[0 0 1 1 1 1 1 1]\n",
      "True:[0 0 1 0 1 1 1 1]\n",
      "False\n",
      "33 + 14 = 63\n",
      "------------\n",
      "Error:[3.27911476]\n",
      "Pred:[0 1 1 0 0 0 1 1]\n",
      "True:[0 1 0 1 0 0 1 1]\n",
      "False\n",
      "24 + 59 = 99\n",
      "------------\n",
      "Error:[3.91718754]\n",
      "Pred:[1 1 0 0 1 0 1 1]\n",
      "True:[1 0 1 1 0 0 0 1]\n",
      "False\n",
      "52 + 125 = 203\n",
      "------------\n",
      "Error:[2.84676144]\n",
      "Pred:[1 1 0 1 1 0 1 0]\n",
      "True:[1 1 0 1 1 0 1 0]\n",
      "True\n",
      "98 + 120 = 218\n",
      "------------\n",
      "Error:[3.56648456]\n",
      "Pred:[0 1 0 0 1 1 1 0]\n",
      "True:[0 1 0 1 0 0 0 0]\n",
      "False\n",
      "37 + 43 = 78\n",
      "------------\n",
      "Error:[2.61810298]\n",
      "Pred:[1 1 1 0 0 1 1 1]\n",
      "True:[1 1 0 0 0 0 1 1]\n",
      "False\n",
      "97 + 98 = 231\n",
      "------------\n",
      "Error:[2.34280248]\n",
      "Pred:[1 0 0 1 1 0 0 0]\n",
      "True:[1 1 0 1 1 0 0 0]\n",
      "False\n",
      "112 + 104 = 152\n",
      "------------\n",
      "Error:[3.83818822]\n",
      "Pred:[0 1 1 1 1 0 1 0]\n",
      "True:[1 0 0 0 0 0 1 0]\n",
      "False\n",
      "120 + 10 = 122\n",
      "------------\n",
      "Error:[2.57289539]\n",
      "Pred:[0 1 1 0 0 1 1 0]\n",
      "True:[0 1 1 0 0 1 1 0]\n",
      "True\n",
      "16 + 86 = 102\n",
      "------------\n",
      "Error:[3.31327062]\n",
      "Pred:[1 1 0 0 1 0 0 0]\n",
      "True:[1 0 0 0 1 0 1 0]\n",
      "False\n",
      "19 + 119 = 200\n",
      "------------\n",
      "Error:[2.69438107]\n",
      "Pred:[1 0 0 1 1 0 0 1]\n",
      "True:[1 1 0 1 0 0 0 1]\n",
      "False\n",
      "100 + 109 = 153\n",
      "------------\n",
      "Error:[2.95509023]\n",
      "Pred:[1 0 1 1 1 0 0 1]\n",
      "True:[1 0 1 1 0 0 0 1]\n",
      "False\n",
      "111 + 66 = 185\n",
      "------------\n",
      "Error:[2.24368312]\n",
      "Pred:[0 1 0 1 1 1 0 1]\n",
      "True:[0 1 0 1 1 1 0 1]\n",
      "True\n",
      "24 + 69 = 93\n",
      "------------\n",
      "Error:[3.63229369]\n",
      "Pred:[1 0 1 1 0 1 0 0]\n",
      "True:[1 1 0 0 0 1 0 0]\n",
      "False\n",
      "78 + 118 = 180\n",
      "------------\n",
      "Error:[2.52654005]\n",
      "Pred:[1 1 0 0 1 1 1 1]\n",
      "True:[1 1 0 0 1 1 1 1]\n",
      "True\n",
      "110 + 97 = 207\n",
      "------------\n",
      "Error:[2.83996122]\n",
      "Pred:[1 1 1 0 1 0 0 1]\n",
      "True:[1 1 1 0 1 0 0 1]\n",
      "True\n",
      "111 + 122 = 233\n",
      "------------\n",
      "Error:[1.07711253]\n",
      "Pred:[0 1 1 0 0 0 1 0]\n",
      "True:[0 1 1 0 0 0 1 0]\n",
      "True\n",
      "97 + 1 = 98\n",
      "------------\n",
      "Error:[1.51067066]\n",
      "Pred:[1 0 0 1 0 0 0 0]\n",
      "True:[1 0 0 1 0 0 0 0]\n",
      "True\n",
      "72 + 72 = 144\n",
      "------------\n",
      "Error:[1.24360068]\n",
      "Pred:[0 1 1 0 1 1 1 0]\n",
      "True:[0 1 1 0 1 1 1 0]\n",
      "True\n",
      "85 + 25 = 110\n",
      "------------\n",
      "Error:[3.40019024]\n",
      "Pred:[1 0 1 1 1 1 1 1]\n",
      "True:[0 1 1 1 1 1 1 1]\n",
      "False\n",
      "66 + 61 = 191\n",
      "------------\n",
      "Error:[1.63590052]\n",
      "Pred:[1 0 0 0 0 0 1 1]\n",
      "True:[1 0 0 0 0 0 1 1]\n",
      "True\n",
      "98 + 33 = 131\n",
      "------------\n",
      "Error:[2.72216248]\n",
      "Pred:[1 0 0 0 0 0 0 0]\n",
      "True:[1 0 0 0 1 0 0 0]\n",
      "False\n",
      "107 + 29 = 128\n",
      "------------\n",
      "Error:[0.53601483]\n",
      "Pred:[0 1 0 1 0 1 0 1]\n",
      "True:[0 1 0 1 0 1 0 1]\n",
      "True\n",
      "16 + 69 = 85\n",
      "------------\n",
      "Error:[1.53384966]\n",
      "Pred:[1 0 1 0 1 1 1 0]\n",
      "True:[1 0 1 0 1 1 1 0]\n",
      "True\n",
      "89 + 85 = 174\n",
      "------------\n",
      "Error:[1.23589765]\n",
      "Pred:[0 1 0 0 1 1 1 0]\n",
      "True:[0 1 0 0 1 1 1 0]\n",
      "True\n",
      "32 + 46 = 78\n",
      "------------\n",
      "Error:[1.52746406]\n",
      "Pred:[1 1 0 1 1 0 0 1]\n",
      "True:[1 1 0 1 1 0 0 1]\n",
      "True\n",
      "122 + 95 = 217\n",
      "------------\n",
      "Error:[0.8104674]\n",
      "Pred:[0 1 1 1 1 1 1 0]\n",
      "True:[0 1 1 1 1 1 1 0]\n",
      "True\n",
      "62 + 64 = 126\n",
      "------------\n",
      "Error:[1.41268677]\n",
      "Pred:[1 0 1 1 1 0 0 0]\n",
      "True:[1 0 1 1 1 0 0 0]\n",
      "True\n",
      "106 + 78 = 184\n",
      "------------\n",
      "Error:[1.58945965]\n",
      "Pred:[0 1 1 1 1 0 1 1]\n",
      "True:[0 1 1 1 1 0 1 1]\n",
      "True\n",
      "95 + 28 = 123\n",
      "------------\n",
      "Error:[1.57149055]\n",
      "Pred:[1 0 1 1 0 1 1 1]\n",
      "True:[1 0 1 1 0 1 1 1]\n",
      "True\n",
      "109 + 74 = 183\n",
      "------------\n",
      "Error:[0.99503431]\n",
      "Pred:[1 1 1 1 0 1 1 1]\n",
      "True:[1 1 1 1 0 1 1 1]\n",
      "True\n",
      "122 + 125 = 247\n",
      "------------\n",
      "Error:[1.23742639]\n",
      "Pred:[1 1 0 0 0 1 1 1]\n",
      "True:[1 1 0 0 0 1 1 1]\n",
      "True\n",
      "79 + 120 = 199\n",
      "------------\n",
      "Error:[1.00171615]\n",
      "Pred:[1 0 1 0 0 1 1 1]\n",
      "True:[1 0 1 0 0 1 1 1]\n",
      "True\n",
      "42 + 125 = 167\n",
      "------------\n",
      "Error:[0.88834079]\n",
      "Pred:[1 0 0 1 0 1 1 0]\n",
      "True:[1 0 0 1 0 1 1 0]\n",
      "True\n",
      "126 + 24 = 150\n",
      "------------\n",
      "Error:[0.62501817]\n",
      "Pred:[1 1 0 0 0 0 0 1]\n",
      "True:[1 1 0 0 0 0 0 1]\n",
      "True\n",
      "112 + 81 = 193\n",
      "------------\n",
      "Error:[0.68401851]\n",
      "Pred:[0 1 0 1 0 1 0 1]\n",
      "True:[0 1 0 1 0 1 0 1]\n",
      "True\n",
      "71 + 14 = 85\n",
      "------------\n",
      "Error:[0.35307906]\n",
      "Pred:[0 1 0 1 0 1 1 0]\n",
      "True:[0 1 0 1 0 1 1 0]\n",
      "True\n",
      "82 + 4 = 86\n",
      "------------\n",
      "Error:[1.27283888]\n",
      "Pred:[1 0 0 0 0 0 0 1]\n",
      "True:[1 0 0 0 0 0 0 1]\n",
      "True\n",
      "30 + 99 = 129\n",
      "------------\n",
      "Error:[0.59094215]\n",
      "Pred:[0 1 0 1 0 0 1 0]\n",
      "True:[0 1 0 1 0 0 1 0]\n",
      "True\n",
      "78 + 4 = 82\n",
      "------------\n",
      "Error:[0.58736554]\n",
      "Pred:[1 0 0 1 1 1 0 1]\n",
      "True:[1 0 0 1 1 1 0 1]\n",
      "True\n",
      "82 + 75 = 157\n",
      "------------\n",
      "Error:[0.38656398]\n",
      "Pred:[1 0 0 0 1 1 0 1]\n",
      "True:[1 0 0 0 1 1 0 1]\n",
      "True\n",
      "77 + 64 = 141\n",
      "------------\n",
      "Error:[0.43420519]\n",
      "Pred:[0 0 1 1 0 0 1 1]\n",
      "True:[0 0 1 1 0 0 1 1]\n",
      "True\n",
      "26 + 25 = 51\n",
      "------------\n",
      "Error:[0.50252171]\n",
      "Pred:[1 0 1 0 0 1 1 0]\n",
      "True:[1 0 1 0 0 1 1 0]\n",
      "True\n",
      "80 + 86 = 166\n",
      "------------\n",
      "Error:[0.66292361]\n",
      "Pred:[1 0 0 1 1 0 0 1]\n",
      "True:[1 0 0 1 1 0 0 1]\n",
      "True\n",
      "42 + 111 = 153\n",
      "------------\n",
      "Error:[0.61874068]\n",
      "Pred:[1 1 0 0 1 1 0 0]\n",
      "True:[1 1 0 0 1 1 0 0]\n",
      "True\n",
      "117 + 87 = 204\n",
      "------------\n",
      "Error:[0.39324392]\n",
      "Pred:[1 0 0 0 1 1 1 0]\n",
      "True:[1 0 0 0 1 1 1 0]\n",
      "True\n",
      "65 + 77 = 142\n",
      "------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:[0.45513889]\n",
      "Pred:[0 1 0 1 0 0 1 1]\n",
      "True:[0 1 0 1 0 0 1 1]\n",
      "True\n",
      "70 + 13 = 83\n",
      "------------\n",
      "Error:[0.27921542]\n",
      "Pred:[0 1 0 1 1 0 1 1]\n",
      "True:[0 1 0 1 1 0 1 1]\n",
      "True\n",
      "90 + 1 = 91\n",
      "------------\n",
      "Error:[0.62198489]\n",
      "Pred:[1 1 1 1 0 1 0 1]\n",
      "True:[1 1 1 1 0 1 0 1]\n",
      "True\n",
      "127 + 118 = 245\n",
      "------------\n",
      "Error:[0.50229076]\n",
      "Pred:[1 0 0 1 0 1 0 1]\n",
      "True:[1 0 0 1 0 1 0 1]\n",
      "True\n",
      "57 + 92 = 149\n",
      "------------\n",
      "Error:[0.58217015]\n",
      "Pred:[0 1 1 1 0 0 0 0]\n",
      "True:[0 1 1 1 0 0 0 0]\n",
      "True\n",
      "21 + 91 = 112\n",
      "------------\n",
      "Error:[0.50710971]\n",
      "Pred:[1 0 1 1 1 0 1 0]\n",
      "True:[1 0 1 1 1 0 1 0]\n",
      "True\n",
      "115 + 71 = 186\n",
      "------------\n",
      "Error:[0.51719454]\n",
      "Pred:[0 1 1 1 0 0 0 1]\n",
      "True:[0 1 1 1 0 0 0 1]\n",
      "True\n",
      "18 + 95 = 113\n",
      "------------\n",
      "Error:[0.47046102]\n",
      "Pred:[1 1 1 0 1 1 1 0]\n",
      "True:[1 1 1 0 1 1 1 0]\n",
      "True\n",
      "116 + 122 = 238\n",
      "------------\n",
      "Error:[0.51538252]\n",
      "Pred:[0 1 0 1 0 0 0 1]\n",
      "True:[0 1 0 1 0 0 0 1]\n",
      "True\n",
      "47 + 34 = 81\n",
      "------------\n",
      "Error:[0.48485176]\n",
      "Pred:[1 0 1 1 0 0 0 1]\n",
      "True:[1 0 1 1 0 0 0 1]\n",
      "True\n",
      "73 + 104 = 177\n",
      "------------\n",
      "Error:[0.45145853]\n",
      "Pred:[1 0 1 0 1 0 1 0]\n",
      "True:[1 0 1 0 1 0 1 0]\n",
      "True\n",
      "77 + 93 = 170\n",
      "------------\n",
      "Error:[0.38580434]\n",
      "Pred:[1 0 0 1 1 1 0 1]\n",
      "True:[1 0 0 1 1 1 0 1]\n",
      "True\n",
      "116 + 41 = 157\n",
      "------------\n",
      "Error:[0.25024716]\n",
      "Pred:[1 0 0 1 0 0 0 1]\n",
      "True:[1 0 0 1 0 0 0 1]\n",
      "True\n",
      "80 + 65 = 145\n",
      "------------\n",
      "Error:[0.18765659]\n",
      "Pred:[0 0 1 0 1 0 1 1]\n",
      "True:[0 0 1 0 1 0 1 1]\n",
      "True\n",
      "2 + 41 = 43\n",
      "------------\n",
      "Error:[0.48164219]\n",
      "Pred:[1 0 1 1 1 0 1 1]\n",
      "True:[1 0 1 1 1 0 1 1]\n",
      "True\n",
      "124 + 63 = 187\n",
      "------------\n",
      "Error:[0.52533063]\n",
      "Pred:[1 0 0 1 1 0 1 1]\n",
      "True:[1 0 0 1 1 0 1 1]\n",
      "True\n",
      "52 + 103 = 155\n",
      "------------\n",
      "Error:[0.14392675]\n",
      "Pred:[0 1 0 1 0 0 1 0]\n",
      "True:[0 1 0 1 0 0 1 0]\n",
      "True\n",
      "81 + 1 = 82\n",
      "------------\n",
      "Error:[0.2536919]\n",
      "Pred:[0 0 0 1 1 0 0 1]\n",
      "True:[0 0 0 1 1 0 0 1]\n",
      "True\n",
      "20 + 5 = 25\n",
      "------------\n",
      "Error:[0.4577056]\n",
      "Pred:[1 0 1 0 0 0 0 1]\n",
      "True:[1 0 1 0 0 0 0 1]\n",
      "True\n",
      "90 + 71 = 161\n",
      "------------\n",
      "Error:[0.35454413]\n",
      "Pred:[0 1 1 0 0 0 0 1]\n",
      "True:[0 1 1 0 0 0 0 1]\n",
      "True\n",
      "72 + 25 = 97\n",
      "------------\n",
      "Error:[0.3027905]\n",
      "Pred:[0 1 0 1 0 0 0 0]\n",
      "True:[0 1 0 1 0 0 0 0]\n",
      "True\n",
      "11 + 69 = 80\n",
      "------------\n",
      "Error:[0.32028173]\n",
      "Pred:[0 1 0 0 0 1 0 0]\n",
      "True:[0 1 0 0 0 1 0 0]\n",
      "True\n",
      "49 + 19 = 68\n",
      "------------\n",
      "Error:[0.47741899]\n",
      "Pred:[1 0 1 1 0 0 1 1]\n",
      "True:[1 0 1 1 0 0 1 1]\n",
      "True\n",
      "70 + 109 = 179\n",
      "------------\n",
      "Error:[0.19099271]\n",
      "Pred:[0 1 0 1 1 0 1 1]\n",
      "True:[0 1 0 1 1 0 1 1]\n",
      "True\n",
      "18 + 73 = 91\n",
      "------------\n",
      "Error:[0.44434423]\n",
      "Pred:[1 1 0 1 0 0 1 1]\n",
      "True:[1 1 0 1 0 0 1 1]\n",
      "True\n",
      "111 + 100 = 211\n",
      "------------\n",
      "Error:[0.34579419]\n",
      "Pred:[1 0 0 1 1 0 0 0]\n",
      "True:[1 0 0 1 1 0 0 0]\n",
      "True\n",
      "73 + 79 = 152\n",
      "------------\n",
      "Error:[0.16166863]\n",
      "Pred:[0 1 1 1 0 1 1 0]\n",
      "True:[0 1 1 1 0 1 1 0]\n",
      "True\n",
      "113 + 5 = 118\n",
      "------------\n",
      "Error:[0.18488997]\n",
      "Pred:[0 0 1 1 0 1 1 1]\n",
      "True:[0 0 1 1 0 1 1 1]\n",
      "True\n",
      "2 + 53 = 55\n",
      "------------\n",
      "Error:[0.39762466]\n",
      "Pred:[1 0 0 1 0 1 1 0]\n",
      "True:[1 0 0 1 0 1 1 0]\n",
      "True\n",
      "127 + 23 = 150\n",
      "------------\n",
      "Error:[0.30393507]\n",
      "Pred:[0 1 1 0 1 1 1 1]\n",
      "True:[0 1 1 0 1 1 1 1]\n",
      "True\n",
      "97 + 14 = 111\n",
      "------------\n",
      "Error:[0.43896228]\n",
      "Pred:[1 0 1 0 1 1 0 0]\n",
      "True:[1 0 1 0 1 1 0 0]\n",
      "True\n",
      "78 + 94 = 172\n",
      "------------\n",
      "Error:[0.19477698]\n",
      "Pred:[0 1 1 0 0 1 1 0]\n",
      "True:[0 1 1 0 0 1 1 0]\n",
      "True\n",
      "36 + 66 = 102\n",
      "------------\n",
      "Error:[0.384797]\n",
      "Pred:[1 0 1 1 0 1 0 0]\n",
      "True:[1 0 1 1 0 1 0 0]\n",
      "True\n",
      "63 + 117 = 180\n",
      "------------\n",
      "Error:[0.24173037]\n",
      "Pred:[0 1 1 1 1 1 1 1]\n",
      "True:[0 1 1 1 1 1 1 1]\n",
      "True\n",
      "68 + 59 = 127\n",
      "------------\n",
      "Error:[0.40062057]\n",
      "Pred:[0 1 0 1 0 1 0 1]\n",
      "True:[0 1 0 1 0 1 0 1]\n",
      "True\n",
      "27 + 58 = 85\n",
      "------------\n",
      "Error:[0.4056001]\n",
      "Pred:[0 1 0 0 0 1 0 1]\n",
      "True:[0 1 0 0 0 1 0 1]\n",
      "True\n",
      "63 + 6 = 69\n",
      "------------\n",
      "Error:[0.41176447]\n",
      "Pred:[1 0 0 1 1 1 1 1]\n",
      "True:[1 0 0 1 1 1 1 1]\n",
      "True\n",
      "127 + 32 = 159\n",
      "------------\n",
      "Error:[0.45722834]\n",
      "Pred:[1 1 0 0 1 0 0 0]\n",
      "True:[1 1 0 0 1 0 0 0]\n",
      "True\n",
      "106 + 94 = 200\n",
      "------------\n",
      "Error:[0.26925754]\n",
      "Pred:[0 1 1 0 1 1 1 0]\n",
      "True:[0 1 1 0 1 1 1 0]\n",
      "True\n",
      "80 + 30 = 110\n",
      "------------\n",
      "Error:[0.18420419]\n",
      "Pred:[0 0 0 1 1 1 0 0]\n",
      "True:[0 0 0 1 1 1 0 0]\n",
      "True\n",
      "23 + 5 = 28\n",
      "------------\n",
      "Error:[0.42250863]\n",
      "Pred:[1 1 0 1 0 0 1 0]\n",
      "True:[1 1 0 1 0 0 1 0]\n",
      "True\n",
      "102 + 108 = 210\n",
      "------------\n",
      "Error:[0.15972739]\n",
      "Pred:[0 0 1 1 1 0 1 0]\n",
      "True:[0 0 1 1 1 0 1 0]\n",
      "True\n",
      "18 + 40 = 58\n",
      "------------\n",
      "Error:[0.36053754]\n",
      "Pred:[1 0 0 1 0 1 0 0]\n",
      "True:[1 0 0 1 0 1 0 0]\n",
      "True\n",
      "95 + 53 = 148\n",
      "------------\n",
      "Error:[0.12271426]\n",
      "Pred:[0 0 0 0 1 1 0 1]\n",
      "True:[0 0 0 0 1 1 0 1]\n",
      "True\n",
      "5 + 8 = 13\n",
      "------------\n",
      "Error:[0.29394636]\n",
      "Pred:[0 1 1 0 0 1 1 0]\n",
      "True:[0 1 1 0 0 1 1 0]\n",
      "True\n",
      "15 + 87 = 102\n",
      "------------\n",
      "Error:[0.43435847]\n",
      "Pred:[1 0 1 0 0 0 0 0]\n",
      "True:[1 0 1 0 0 0 0 0]\n",
      "True\n",
      "101 + 59 = 160\n",
      "------------\n",
      "Error:[0.25130702]\n",
      "Pred:[0 0 1 0 0 1 0 0]\n",
      "True:[0 0 1 0 0 1 0 0]\n",
      "True\n",
      "31 + 5 = 36\n",
      "------------\n",
      "Error:[0.37297311]\n",
      "Pred:[0 1 0 1 0 0 1 0]\n",
      "True:[0 1 0 1 0 0 1 0]\n",
      "True\n",
      "54 + 28 = 82\n",
      "------------\n",
      "Error:[0.23398697]\n",
      "Pred:[0 0 0 1 1 0 1 0]\n",
      "True:[0 0 0 1 1 0 1 0]\n",
      "True\n",
      "12 + 14 = 26\n",
      "------------\n",
      "Error:[0.33698497]\n",
      "Pred:[0 1 1 1 1 0 1 0]\n",
      "True:[0 1 1 1 1 0 1 0]\n",
      "True\n",
      "110 + 12 = 122\n",
      "------------\n",
      "Error:[0.32293045]\n",
      "Pred:[0 1 0 1 0 0 0 0]\n",
      "True:[0 1 0 1 0 0 0 0]\n",
      "True\n",
      "74 + 6 = 80\n",
      "------------\n",
      "Error:[0.29383664]\n",
      "Pred:[0 1 0 0 1 0 0 1]\n",
      "True:[0 1 0 0 1 0 0 1]\n",
      "True\n",
      "28 + 45 = 73\n",
      "------------\n",
      "Error:[0.29335243]\n",
      "Pred:[1 0 0 1 1 0 1 0]\n",
      "True:[1 0 0 1 1 0 1 0]\n",
      "True\n",
      "53 + 101 = 154\n",
      "------------\n",
      "Error:[0.37123225]\n",
      "Pred:[1 1 1 0 1 1 0 0]\n",
      "True:[1 1 1 0 1 1 0 0]\n",
      "True\n",
      "126 + 110 = 236\n",
      "------------\n",
      "Error:[0.26784038]\n",
      "Pred:[1 1 0 1 1 1 1 0]\n",
      "True:[1 1 0 1 1 1 1 0]\n",
      "True\n",
      "122 + 100 = 222\n",
      "------------\n",
      "Error:[0.34925971]\n",
      "Pred:[0 0 1 1 0 1 1 1]\n",
      "True:[0 0 1 1 0 1 1 1]\n",
      "True\n",
      "15 + 40 = 55\n",
      "------------\n",
      "Error:[0.2196544]\n",
      "Pred:[0 1 1 0 1 1 1 0]\n",
      "True:[0 1 1 0 1 1 1 0]\n",
      "True\n",
      "25 + 85 = 110\n",
      "------------\n",
      "Error:[0.14428875]\n",
      "Pred:[0 1 0 0 1 0 1 0]\n",
      "True:[0 1 0 0 1 0 1 0]\n",
      "True\n",
      "7 + 67 = 74\n",
      "------------\n",
      "Error:[0.30459088]\n",
      "Pred:[0 1 0 0 0 0 0 0]\n",
      "True:[0 1 0 0 0 0 0 0]\n",
      "True\n",
      "63 + 1 = 64\n",
      "------------\n",
      "Error:[0.1506828]\n",
      "Pred:[0 1 1 1 1 0 1 1]\n",
      "True:[0 1 1 1 1 0 1 1]\n",
      "True\n",
      "64 + 59 = 123\n",
      "------------\n",
      "Error:[0.27649987]\n",
      "Pred:[0 1 0 1 1 1 0 0]\n",
      "True:[0 1 0 1 1 1 0 0]\n",
      "True\n",
      "50 + 42 = 92\n",
      "------------\n",
      "Error:[0.27844325]\n",
      "Pred:[1 1 0 0 0 0 1 0]\n",
      "True:[1 1 0 0 0 0 1 0]\n",
      "True\n",
      "77 + 117 = 194\n",
      "------------\n",
      "Error:[0.29936468]\n",
      "Pred:[0 1 0 1 0 0 0 0]\n",
      "True:[0 1 0 1 0 0 0 0]\n",
      "True\n",
      "33 + 47 = 80\n",
      "------------\n",
      "Error:[0.17910203]\n",
      "Pred:[1 0 0 1 1 0 1 1]\n",
      "True:[1 0 0 1 1 0 1 1]\n",
      "True\n",
      "82 + 73 = 155\n",
      "------------\n",
      "Error:[0.19257083]\n",
      "Pred:[1 0 1 1 1 1 0 1]\n",
      "True:[1 0 1 1 1 1 0 1]\n",
      "True\n",
      "105 + 84 = 189\n",
      "------------\n",
      "Error:[0.12016148]\n",
      "Pred:[0 1 0 0 1 1 1 0]\n",
      "True:[0 1 0 0 1 1 1 0]\n",
      "True\n",
      "11 + 67 = 78\n",
      "------------\n",
      "Error:[0.26722366]\n",
      "Pred:[1 0 1 0 1 1 1 0]\n",
      "True:[1 0 1 0 1 1 1 0]\n",
      "True\n",
      "112 + 62 = 174\n",
      "------------\n",
      "Error:[0.28009711]\n",
      "Pred:[1 0 1 0 0 1 0 1]\n",
      "True:[1 0 1 0 0 1 0 1]\n",
      "True\n",
      "108 + 57 = 165\n",
      "------------\n",
      "Error:[0.22371447]\n",
      "Pred:[0 1 1 1 0 0 1 0]\n",
      "True:[0 1 1 1 0 0 1 0]\n",
      "True\n",
      "15 + 99 = 114\n",
      "------------\n",
      "Error:[0.27980071]\n",
      "Pred:[1 0 1 0 0 1 1 1]\n",
      "True:[1 0 1 0 0 1 1 1]\n",
      "True\n",
      "113 + 54 = 167\n",
      "------------\n",
      "Error:[0.22918159]\n",
      "Pred:[0 0 0 1 1 1 1 1]\n",
      "True:[0 0 0 1 1 1 1 1]\n",
      "True\n",
      "1 + 30 = 31\n",
      "------------\n",
      "Error:[0.31937504]\n",
      "Pred:[1 0 1 1 0 0 1 1]\n",
      "True:[1 0 1 1 0 0 1 1]\n",
      "True\n",
      "102 + 77 = 179\n",
      "------------\n",
      "Error:[0.22852688]\n",
      "Pred:[1 1 1 0 0 1 1 0]\n",
      "True:[1 1 1 0 0 1 1 0]\n",
      "True\n",
      "112 + 118 = 230\n",
      "------------\n",
      "Error:[0.19959135]\n",
      "Pred:[1 1 0 1 0 0 1 0]\n",
      "True:[1 1 0 1 0 0 1 0]\n",
      "True\n",
      "121 + 89 = 210\n",
      "------------\n",
      "Error:[0.12430546]\n",
      "Pred:[0 1 0 0 1 1 0 0]\n",
      "True:[0 1 0 0 1 1 0 0]\n",
      "True\n",
      "4 + 72 = 76\n",
      "------------\n",
      "Error:[0.22408818]\n",
      "Pred:[0 1 0 0 0 1 1 0]\n",
      "True:[0 1 0 0 0 1 1 0]\n",
      "True\n",
      "48 + 22 = 70\n",
      "------------\n",
      "Error:[0.20221729]\n",
      "Pred:[1 0 1 0 0 1 1 0]\n",
      "True:[1 0 1 0 0 1 1 0]\n",
      "True\n",
      "115 + 51 = 166\n",
      "------------\n",
      "Error:[0.17104793]\n",
      "Pred:[1 0 0 0 1 0 1 0]\n",
      "True:[1 0 0 0 1 0 1 0]\n",
      "True\n",
      "71 + 67 = 138\n",
      "------------\n",
      "Error:[0.29566632]\n",
      "Pred:[1 0 0 0 0 1 1 1]\n",
      "True:[1 0 0 0 0 1 1 1]\n",
      "True\n",
      "125 + 10 = 135\n",
      "------------\n",
      "Error:[0.26591579]\n",
      "Pred:[1 0 1 0 1 0 0 1]\n",
      "True:[1 0 1 0 1 0 0 1]\n",
      "True\n",
      "95 + 74 = 169\n",
      "------------\n",
      "Error:[0.23643373]\n",
      "Pred:[0 0 1 0 0 1 1 0]\n",
      "True:[0 0 1 0 0 1 1 0]\n",
      "True\n",
      "28 + 10 = 38\n",
      "------------\n",
      "Error:[0.29028257]\n",
      "Pred:[1 0 1 1 0 0 1 0]\n",
      "True:[1 0 1 1 0 0 1 0]\n",
      "True\n",
      "55 + 123 = 178\n",
      "------------\n",
      "Error:[0.23127843]\n",
      "Pred:[1 1 0 0 1 1 0 1]\n",
      "True:[1 1 0 0 1 1 0 1]\n",
      "True\n",
      "88 + 117 = 205\n",
      "------------\n",
      "Error:[0.21379392]\n",
      "Pred:[1 0 0 0 0 1 1 1]\n",
      "True:[1 0 0 0 0 1 1 1]\n",
      "True\n",
      "98 + 37 = 135\n",
      "------------\n",
      "Error:[0.28917566]\n",
      "Pred:[1 0 1 0 1 0 0 1]\n",
      "True:[1 0 1 0 1 0 0 1]\n",
      "True\n",
      "111 + 58 = 169\n",
      "------------\n",
      "Error:[0.25232534]\n",
      "Pred:[1 1 0 1 1 1 0 0]\n",
      "True:[1 1 0 1 1 1 0 0]\n",
      "True\n",
      "95 + 125 = 220\n",
      "------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:[0.23058793]\n",
      "Pred:[1 0 1 0 1 0 1 0]\n",
      "True:[1 0 1 0 1 0 1 0]\n",
      "True\n",
      "88 + 82 = 170\n",
      "------------\n",
      "Error:[0.30600955]\n",
      "Pred:[1 0 0 0 0 0 0 1]\n",
      "True:[1 0 0 0 0 0 0 1]\n",
      "True\n",
      "99 + 30 = 129\n",
      "------------\n",
      "Error:[0.24408132]\n",
      "Pred:[0 1 0 1 1 0 0 0]\n",
      "True:[0 1 0 1 1 0 0 0]\n",
      "True\n",
      "52 + 36 = 88\n",
      "------------\n",
      "Error:[0.26199122]\n",
      "Pred:[1 0 0 1 1 0 1 0]\n",
      "True:[1 0 0 1 1 0 1 0]\n",
      "True\n",
      "127 + 27 = 154\n",
      "------------\n",
      "Error:[0.2308597]\n",
      "Pred:[1 1 0 1 1 1 0 0]\n",
      "True:[1 1 0 1 1 1 0 0]\n",
      "True\n",
      "106 + 114 = 220\n",
      "------------\n",
      "Error:[0.26871153]\n",
      "Pred:[1 0 0 0 1 0 0 0]\n",
      "True:[1 0 0 0 1 0 0 0]\n",
      "True\n",
      "21 + 115 = 136\n",
      "------------\n",
      "Error:[0.14836389]\n",
      "Pred:[0 1 1 1 0 1 1 1]\n",
      "True:[0 1 1 1 0 1 1 1]\n",
      "True\n",
      "99 + 20 = 119\n",
      "------------\n",
      "Error:[0.26056678]\n",
      "Pred:[1 1 1 1 0 1 1 1]\n",
      "True:[1 1 1 1 0 1 1 1]\n",
      "True\n",
      "126 + 121 = 247\n",
      "------------\n",
      "Error:[0.21699123]\n",
      "Pred:[0 1 0 0 0 1 1 1]\n",
      "True:[0 1 0 0 0 1 1 1]\n",
      "True\n",
      "52 + 19 = 71\n",
      "------------\n",
      "Error:[0.15114712]\n",
      "Pred:[0 1 1 1 0 0 1 1]\n",
      "True:[0 1 1 1 0 0 1 1]\n",
      "True\n",
      "51 + 64 = 115\n",
      "------------\n",
      "Error:[0.23657825]\n",
      "Pred:[1 0 0 1 1 1 1 1]\n",
      "True:[1 0 0 1 1 1 1 1]\n",
      "True\n",
      "54 + 105 = 159\n",
      "------------\n",
      "Error:[0.21836464]\n",
      "Pred:[1 1 1 1 1 0 1 0]\n",
      "True:[1 1 1 1 1 0 1 0]\n",
      "True\n",
      "125 + 125 = 250\n",
      "------------\n",
      "Error:[0.11765047]\n",
      "Pred:[0 1 1 0 1 0 1 1]\n",
      "True:[0 1 1 0 1 0 1 1]\n",
      "True\n",
      "42 + 65 = 107\n",
      "------------\n",
      "Error:[0.22654752]\n",
      "Pred:[0 1 1 1 1 1 1 1]\n",
      "True:[0 1 1 1 1 1 1 1]\n",
      "True\n",
      "97 + 30 = 127\n",
      "------------\n",
      "Error:[0.09659835]\n",
      "Pred:[0 1 1 1 0 1 0 1]\n",
      "True:[0 1 1 1 0 1 0 1]\n",
      "True\n",
      "32 + 85 = 117\n",
      "------------\n",
      "Error:[0.20630273]\n",
      "Pred:[1 1 1 1 0 0 1 1]\n",
      "True:[1 1 1 1 0 0 1 1]\n",
      "True\n",
      "120 + 123 = 243\n",
      "------------\n",
      "Error:[0.19706751]\n",
      "Pred:[0 1 1 1 0 1 0 0]\n",
      "True:[0 1 1 1 0 1 0 0]\n",
      "True\n",
      "21 + 95 = 116\n",
      "------------\n",
      "Error:[0.22943276]\n",
      "Pred:[1 0 1 0 0 0 1 0]\n",
      "True:[1 0 1 0 0 0 1 0]\n",
      "True\n",
      "104 + 58 = 162\n",
      "------------\n",
      "Error:[0.23257017]\n",
      "Pred:[0 1 1 0 0 0 1 1]\n",
      "True:[0 1 1 0 0 0 1 1]\n",
      "True\n",
      "22 + 77 = 99\n",
      "------------\n",
      "Error:[0.15080149]\n",
      "Pred:[0 1 0 1 1 1 1 0]\n",
      "True:[0 1 0 1 1 1 1 0]\n",
      "True\n",
      "45 + 49 = 94\n",
      "------------\n",
      "Error:[0.12567795]\n",
      "Pred:[0 0 1 1 0 1 1 1]\n",
      "True:[0 0 1 1 0 1 1 1]\n",
      "True\n",
      "38 + 17 = 55\n",
      "------------\n",
      "Error:[0.28120981]\n",
      "Pred:[1 1 0 0 0 1 1 0]\n",
      "True:[1 1 0 0 0 1 1 0]\n",
      "True\n",
      "108 + 90 = 198\n",
      "------------\n",
      "Error:[0.32838608]\n",
      "Pred:[1 0 0 0 1 0 0 0]\n",
      "True:[1 0 0 0 1 0 0 0]\n",
      "True\n",
      "110 + 26 = 136\n",
      "------------\n",
      "Error:[0.22691487]\n",
      "Pred:[1 1 0 0 0 1 1 1]\n",
      "True:[1 1 0 0 0 1 1 1]\n",
      "True\n",
      "72 + 127 = 199\n",
      "------------\n",
      "Error:[0.09966136]\n",
      "Pred:[0 0 1 0 0 1 0 0]\n",
      "True:[0 0 1 0 0 1 0 0]\n",
      "True\n",
      "4 + 32 = 36\n",
      "------------\n",
      "Error:[0.23196088]\n",
      "Pred:[0 1 0 1 0 1 1 1]\n",
      "True:[0 1 0 1 0 1 1 1]\n",
      "True\n",
      "28 + 59 = 87\n",
      "------------\n",
      "Error:[0.14169074]\n",
      "Pred:[0 0 0 1 1 0 1 0]\n",
      "True:[0 0 0 1 1 0 1 0]\n",
      "True\n",
      "19 + 7 = 26\n",
      "------------\n",
      "Error:[0.11328021]\n",
      "Pred:[0 1 1 0 1 1 0 0]\n",
      "True:[0 1 1 0 1 1 0 0]\n",
      "True\n",
      "100 + 8 = 108\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "max_iter = 20000\n",
    "for j in range(max_iter):\n",
    "    #  binary lookup table\n",
    "    # Randomly pick two integers and change it to the binary representation\n",
    "    a_int = np.random.randint(1,largest_number//2)\n",
    "    a = int2binary[a_int]\n",
    "    b_int = np.random.randint(1,largest_number//2)\n",
    "    b = int2binary[b_int]\n",
    "    #\n",
    "    # Calculate the answer and save it as a binary form\n",
    "    c_int = a_int + b_int\n",
    "    c = int2binary[c_int]\n",
    "    \n",
    "    # RNN이  binary \n",
    "    # Declare the variable for saving the prediction by RNN\n",
    "    pred = np.zeros_like(c)\n",
    "    \n",
    "    overallError = 0\n",
    "    \n",
    "    output_layer_deltas = list()\n",
    "    hidden_layer_values = list()\n",
    "    hidden_layer_values.append(np.zeros(hidden_dim)) # dim: (1, 16)\n",
    "\n",
    "    # feed forward !\n",
    "\n",
    "    # As you have to calculate from the \"first\" position of the binary number, which stands for the lowest value, loop backward.\n",
    "    # e.g. \n",
    "    # 10(2) + 11(2), for the first iteration: X = [[0,1]] y = [[1]]\n",
    "    for position in reversed(range(max_binary_dim)):\n",
    "        \n",
    "        # RNN  input output label \n",
    "        # Take the input and output label binary values\n",
    "        X = np.array([[a[position],b[position]]]) # dim: (1, 2), e.g. [[1,0]]\n",
    "        y = np.array([[c[position]]]) # dim: (1, 1), e.g. [[1]]\n",
    "        \n",
    "        # hidden layer  h_t = sigmoid(X*W_{hx} + h_{t-1}*W_{hh})\n",
    "        hidden_layer = sigmoid(np.dot(X,synapse_0) + np.dot(hidden_layer_values[-1],synapse_h)) # dim: (1, 16)\n",
    "        \n",
    "        # output_layer \n",
    "        output_layer = sigmoid(np.dot(hidden_layer,synapse_1)) # dim: (1, 1), e.g. [[0.47174173]]\n",
    "        \n",
    "        # error \n",
    "        output_layer_error = y-output_layer # dim: (1, 1) \n",
    "        \n",
    "        # display (just for displying error curve)\n",
    "        overallError += np.abs(output_layer_error[0]) # dim: (1, )          \n",
    "        \n",
    "        # 이  backpropagation delta \n",
    "        # Save it for the later use in backpropagation step        \n",
    "        output_layer_deltas.append((output_layer_error) * sigmoid_output_to_derivative(output_layer))        \n",
    "        \n",
    "       \n",
    "        # save the prediction by my model on this position\n",
    "        pred[position] = np.round(output_layer[0][0])\n",
    "        \n",
    "        \n",
    "        # save the hidden layer by appending the values to the list\n",
    "        hidden_layer_values.append(copy.deepcopy(hidden_layer)) \n",
    "    \n",
    "    if (j%100 == 0):\n",
    "        overallError_history.append(overallError[0])\n",
    "    \n",
    "    # backpropagation !\n",
    "        \n",
    "    \n",
    "    # As RNN needs to consider the \"future\" hidden layer value to calculate the backpropagation and it does not have the \n",
    "    # value at the first time (at the end of the position where backpropagation starts), we have to initialize it with zeros\n",
    "    future_hidden_layer_delta = np.zeros(hidden_dim)\n",
    "    \n",
    "    # backpropagation\n",
    "    # Now it should go \"backward\" which means an ordinary way in the for loop\n",
    "    for position in range(max_binary_dim):\n",
    "        \n",
    "\n",
    "        # bring what you needs for calculation\n",
    "        X = np.array([[a[position],b[position]]])\n",
    "        hidden_layer = hidden_layer_values[-position-1]\n",
    "        prev_hidden_layer = hidden_layer_values[-position-2]\n",
    "        \n",
    "      \n",
    "        # Get the gradients flowing back from the error of my output at this position, or time step\n",
    "        output_layer_delta = output_layer_deltas[-position-1]\n",
    "        \n",
    "        #  hidden layer gradient\n",
    "        #  hidden layer error gradient +  output layer error gradient\n",
    "        # sigmoid derivative \n",
    "        # 이유: h_t = sigmoid(X*W_{hx} + h_{t-1}*W_{hh})\n",
    "        # Important part! (Backpropagation)\n",
    "        # Think about the feed forward step you have done before: h_t = sigmoid(X*W_{hx} + h_{t-1}*W_{hh})\n",
    "        hidden_layer_delta = (np.dot(future_hidden_layer_delta,synapse_h.T) + np.dot(output_layer_delta,synapse_1.T)) \\\n",
    "                            * sigmoid_output_to_derivative(hidden_layer)\n",
    "        \n",
    "        # gradient update \n",
    "        # backprop hidden layer의 value\n",
    "        # Save the updates until the for loop finishes calculation for every position\n",
    "        # Hidden layer values must be changed ONLY AFTER backpropagation is fully done at every position.\n",
    "        s1_update += np.atleast_2d(hidden_layer).T.dot(output_layer_delta)\n",
    "        sh_update += np.atleast_2d(prev_hidden_layer).T.dot(hidden_layer_delta)\n",
    "        s0_update += X.T.dot(hidden_layer_delta)\n",
    "        \n",
    "       \n",
    "        # Preparation for the next step. Now the current hidden_layer_delta becomes the future hidden_layer_delta.\n",
    "        future_hidden_layer_delta = hidden_layer_delta\n",
    "\n",
    "    # weight  update (learning rate)\n",
    "    synapse_1 += s1_update*alpha\n",
    "    synapse_0 += s0_update*alpha\n",
    "    synapse_h += sh_update*alpha\n",
    "    \n",
    "    # update value initialization for the new training data ( a,b training )\n",
    "    s1_update *= 0\n",
    "    s0_update *= 0    \n",
    "    sh_update *= 0\n",
    "    \n",
    "    # accuracy \n",
    "    check = np.equal(pred,c)\n",
    "    if np.sum(check) == max_binary_dim:\n",
    "        accuracy_count += 1\n",
    "    if (j%100 == 0):\n",
    "        accuracy_history.append(accuracy_count)\n",
    "        accuracy_count = 0\n",
    "    \n",
    "    \n",
    "    if (j % 100 == 0):\n",
    "        print (\"Error:\" + str(overallError))\n",
    "        print (\"Pred:\" + str(pred))  \n",
    "        print (\"True:\" + str(c)) \n",
    "\n",
    "        final_check = np.equal(pred,c)\n",
    "        print (np.sum(final_check) == max_binary_dim)\n",
    "\n",
    "        out = 0\n",
    "\n",
    "        for index, x in enumerate(reversed(pred)):\n",
    "            out += x * pow(2, index)\n",
    "        print (str(a_int) + \" + \" + str(b_int) + \" = \" + str(out))\n",
    "        print (\"------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x29694dd5630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x29697814be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(overallError_history)\n",
    "x_range = range(max_iter//100)\n",
    "plt.plot(x_range,overallError_history,'r-')\n",
    "plt.ylabel('overallError')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(x_range,accuracy_history,'b-')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
