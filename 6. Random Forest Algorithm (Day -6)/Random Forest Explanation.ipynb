{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOW THE RANDOM FOREST ALGORITHM WORKS IN MACHINE LEARNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source:https://dataaspirant.com/2017/05/22/random-forest-algorithm-machine-learing/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Random forest algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest algorithm is a supervised classification algorithm. As the name suggest, this algorithm creates the forest with a number of trees.\n",
    "\n",
    "In general, the more trees in the forest the more robust the forest looks like. In the same way in the random forest classifier, the higher the number of trees in the forest gives the high accuracy results.\n",
    "\n",
    "If you know the decision tree algorithm. You might be thinking are we creating more number of decision trees and how can we create more number of decision trees. As all the calculation of nodes selection will be same for the same dataset.\n",
    "\n",
    "Yes. You are true. To model more number of decision trees to create the forest you are not going to use the same apache of constructing the decision with information gain or gini index approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic decision tree concept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision tree concept is more to the rule based system. Given the training dataset with targets and features, the decision tree algorithm will come up with some set of rules. The same set rules can be used to perform the prediction on the test dataset.\n",
    "\n",
    "Suppose you would like to predict that your daughter will like the newly released animation movie or not. To model the decision tree you will use the training dataset like the animated cartoon characters your daughter liked in the past movies.\n",
    "\n",
    "So once you pass the dataset with the target as your daughter will like the movie or not to the decision tree classifier. The decision tree will start building the rules with the characters your daughter like as nodes and the targets like or not as the leaf nodes. By considering the path from the root node to the leaf node. You can get the rules.\n",
    "\n",
    "The simple rule could be if some x character is playing the leading role then your daughter will like the movie. You can think few more rule based on this example.\n",
    "\n",
    "Then to predict whether your daughter will like the movie or not. You just need to check the rules which are created by the decision tree to predict whether your daughter will like the newly released movie or not.\n",
    "\n",
    "In decision tree algorithm calculating these nodes and forming the rules will happen using the information gain and gini index calculations.\n",
    "\n",
    "In random forest algorithm, Instead of using information gain or gini index for calculating the root node, the process of finding the root node and splitting the feature nodes will happen randomly. Will look about in detail in the coming section.\n",
    "\n",
    "Next, you are going to learn why random forest algorithm? When we are having other classification algorithms to play with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why Random forest algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To address why random forest algorithm. I am giving you the below advantages.\n",
    "\n",
    "1.The same random forest algorithm or the random forest classifier can use for both classification and the regression task.'\n",
    "\n",
    "2.Random forest classifier will handle the missing values.\n",
    "\n",
    "3.When we have more trees in the forest, random forest classifier won’t overfit the model.\n",
    "\n",
    "4.Can model the random forest classifier for categorical values also."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest algorithm real life example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i1.wp.com/dataaspirant.com/wp-content/uploads/2017/04/Random-Forest-Example.jpg?w=700&ssl=1\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you drive into the technical details about the random forest algorithm. Let’s look into a real life example to understand the layman type of random forest algorithm.\n",
    "\n",
    "Suppose Mady somehow got 2 weeks leave from his office. He wants to spend his 2 weeks by traveling to the different place. He also wants to go to the place he may like.\n",
    "\n",
    "So he decided to ask his best friend about the places he may like. Then his friend started asking about his past trips. It’s just like his best friend will ask, You have been visited the X place did you like it?\n",
    "\n",
    "Based on the answers which are given by Mady, his best start recommending the place Mady may like. Here his best formed the decision tree with the answer given by Mady.\n",
    "\n",
    "As his best friend may recommend his best place to Mady as a friend. The model will be biased with the closeness of their friendship. So he decided to ask few more friends to recommend the best place he may like.\n",
    "\n",
    "Now his friends asked some random questions and each one recommended one place to Mady. Now  Mady considered the place which is high votes from his friends as the final place to visit.\n",
    "\n",
    "In the above Mady trip planning, two main interesting algorithms decision tree algorithm and random forest algorithm used. I hope you find it already. Anyhow, I would like to highlight it again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To recommend the best place to Mady, his best friend asked some questions. Based on the answers given by mady, he recommended a place. This is decision tree algorithm approach. Will explain why it is a decision tree algorithm approach.\n",
    "\n",
    "Mady friend used the answers given by mady to create rules. Later he used the created rules to recommend the best place which mady will like. These rules could be, mady like a place with lots of tree or waterfalls ..etc\n",
    "\n",
    "In the above approach mady best friend is the decision tree. The vote (recommended place) is the leaf of the decision tree (Target class). The target is finalized by a single person, In a technical way of saying, using an only single decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Algorithm:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the other case when mady asked his friends to recommend the best place to visit. Each friend asked him different questions and come up their recommend a place to visit. Later mady consider all the recommendations and calculated the votes. Votes basically is to pick the popular place from the recommend places from all his friends.\n",
    "\n",
    "Mady will consider each recommended place and if the same place recommended by some other place he will increase the count. At the end the high count place where mady will go.\n",
    "\n",
    "In this case, the recommended place (Target Prediction) is considered by many friends. Each friend is the tree and the combined all friends will form the forest. This forest is the random forest. As each friend asked random questions to recommend the best place visit.\n",
    "\n",
    "Now let’s use the above example to understand how the random forest algorithm work.\n",
    "\n",
    "<img src=\"https://i2.wp.com/dataaspirant.com/wp-content/uploads/2017/04/How-random-forest-algorithm-works.jpg?w=500&ssl=1\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s look at the pseudocode for random forest algorithm and later we can walk through each step in the random forest algorithm.\n",
    "\n",
    "The pseudocode for random forest algorithm can split into two stages.\n",
    "\n",
    "1.Random forest creation pseudocode.\n",
    "\n",
    "2.Pseudocode to perform prediction from the created random forest classifier.\n",
    "\n",
    "First, let’s begin with random forest creation pseudocode"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Random Forest pseudocode:\n",
    "1.Randomly select “k” features from total “m” features.\n",
    "    Where k << m\n",
    "2.Among the “k” features, calculate the node “d” using the best split point.\n",
    "\n",
    "3.Split the node into daughter nodes using the best split.\n",
    "\n",
    "4.Repeat 1 to 3 steps until “l” number of nodes has been reached.\n",
    "\n",
    "5.Build forest by repeating steps 1 to 4 for “n” number times to create “n” number of trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The beginning of random forest algorithm starts with randomly selecting “k” features out of total “m” features. In the image, you can observe that we are randomly taking features and observations.\n",
    "\n",
    "In the next stage, we are using the randomly selected “k” features to find the root node by using the best split approach.\n",
    "\n",
    "The next stage, We will be calculating the daughter nodes using the same best split approach. Will the first 3 stages until we form the tree with a root node and having the target as the leaf node.\n",
    "\n",
    "Finally, we repeat 1 to 4 stages to create “n” randomly created trees. This randomly created trees forms the random forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest prediction pseudocode:\n",
    "To perform prediction using the trained random forest algorithm uses the below pseudocode.\n",
    "\n",
    "1.Takes the test features and use the rules of each randomly created decision tree to predict the oucome and stores the predicted outcome (target)\n",
    "\n",
    "2..Calculate the votes for each predicted target.\n",
    "\n",
    "3.Consider the high voted predicted target as the final prediction from the random forest algorithm.\n",
    "\n",
    "To perform the prediction using the trained random forest algorithm we need to pass the test features through the rules of each randomly created trees. Suppose let’s say we formed 100 random decision trees to from the random forest.\n",
    "\n",
    "Each random forest will predict different target (outcome) for the same test feature. Then by considering each predicted target votes will be calculated. Suppose the 100 random decision trees are prediction some 3 unique targets x, y, z then the votes of x is nothing but out of 100 random decision tree how many trees prediction is x.\n",
    "\n",
    "Likewise for other 2 targets (y, z). If x is getting high votes. Let’s say out of 100 random decision tree 60 trees are predicting the target will be x. Then the final random forest returns the x as the predicted target.\n",
    "\n",
    "This concept of voting is known as majority voting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advantages of random forest algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the advantages of random forest algorithm compared with other classification algorithms.\n",
    "\n",
    "1.The overfitting problem will never come when we use the random forest algorithm in any classification problem.\n",
    "\n",
    "2.The same random forest algorithm can be used for both classification and regression task.\n",
    "\n",
    "3.The random forest algorithm can be used for feature engineering.\n",
    "\n",
    "Which means identifying the most important features out of the available features from the training dataset.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
